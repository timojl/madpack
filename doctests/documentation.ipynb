{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import markdown\n",
    "import torch\n",
    "import madpack\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "from madpack.doc import html_docstring, html_docstring_class\n",
    "from madpack import log\n",
    "log.level = 'info'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(HTML(markdown.markdown(open('../Readme.md', 'r').read())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets\n",
    "\n",
    "## DatasetBase class\n",
    "\n",
    "All dataset in madpack inherit from DatasetBase. Lets take a look at its methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from madpack.datasets import DatasetBase\n",
    "display(HTML(html_docstring_class(DatasetBase)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_type in madpack.datasets.__all__:\n",
    "    if dataset_type != 'DatasetBase':\n",
    "        dt = getattr(madpack.datasets, dataset_type)\n",
    "        display(HTML(html_docstring_class(dt, exclude=('install', '__getitem__', 'check_data_integrity'))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from madpack.datasets import SquareCountDummy\n",
    "dset = SquareCountDummy('train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets can define repository files that are copied to a local folder when required. Per default, the dataset path is `~/datasets` and the repository path is `~/dataset_repositories`, both can be symlinks. They can be overwritten in a config file `~/.config/madpack.yaml`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset.repository_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tuple or list `sample_ids` assigns a unique identifier to each sample of the dataset. In this case it is a parameterization of the squares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset.sample_ids[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When a dataset implements the attribute tuple `sample_ids` it is used to define length. Furthermore, the `resize` option becomes available. Using `split_overlap` the splits can be checked for overlaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('original dataset size', len(dset))\n",
    "\n",
    "dset.resize(100)\n",
    "print('reduced to', len(dset))\n",
    "\n",
    "dset.resize(None)\n",
    "print('and back at', len(dset))\n",
    "\n",
    "print(\"Now let's check for overlap...!\")\n",
    "from madpack.utils import split_overlap\n",
    "split_overlap(SquareCountDummy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from madpack.interactive import *\n",
    "plot_data(dset, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforms\n",
    "\n",
    "It is recommendable too rely on `torchvision`'s transforms as much as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for transform in madpack.transforms.__all__:\n",
    "    display(HTML(html_docstring_class(getattr(madpack.transforms, transform))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from madpack.models import RN18Dense, RN18Narrow\n",
    "import torch\n",
    "\n",
    "inp = torch.zeros(1, 3, 128, 128)\n",
    "out, activations =  RN18Dense()(inp)\n",
    "\n",
    "assert out.shape[2:] == (inp.shape[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from madpack.models import NarrowRN18Dense, RN18Dense\n",
    "\n",
    "from madpack.utils import count_parameters\n",
    "m = NarrowRN18Dense(channels=(32, 32, 16, 16), decoder_shape='xs')\n",
    "print(count_parameters(m), count_parameters(m.resnet), count_parameters(m.decoder2))\n",
    "import torch\n",
    "\n",
    "inp = torch.zeros(1,3,48,48)\n",
    "out = m(inp)\n",
    "\n",
    "assert inp.shape[2:] == out[0].shape[2:]\n",
    "assert out[0].shape[1] == 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from madpack.models import NarrowRN50Dense\n",
    "m = NarrowRN50Dense(channels=(16,16,16,16))\n",
    "\n",
    "out = m(inp)\n",
    "\n",
    "assert inp.shape[2:] == out[0].shape[2:]\n",
    "assert out[0].shape[1] == 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from madpack.transforms import imread\n",
    "from madpack.interactive import *\n",
    "\n",
    "img = imread('sample_image1.jpg')\n",
    "plt.imshow(img.permute(1,2,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale proportionally to size defined by box (here 200 by 200)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_part = img[:, 100:200, 50:110]\n",
    "img_part.shape\n",
    "\n",
    "print(img_part.shape)\n",
    "\n",
    "from madpack.transforms import resize\n",
    "out = resize(img_part, (200, 200), max_bound=True)\n",
    "\n",
    "plt.imshow(out.permute(1,2,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### random crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from madpack.transforms.spatial import random_crop\n",
    "\n",
    "print('before', img.shape)\n",
    "img_crop = random_crop(img, (150, 150), spatial_dims=(1,2))\n",
    "print('after', img_crop.shape)\n",
    "plt.imshow(img_crop.permute(1,2,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from madpack.transforms.spatial import pad_to_square\n",
    "img_square = pad_to_square(img[:, :100, :200], channel_dim=0)\n",
    "img_square2 = pad_to_square(img[:, :100, :200].permute(1,2,0), channel_dim=2)\n",
    "assert img_square.shape[1:] == img_square2.shape[0:2]\n",
    "plt.imshow(img_square2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### random crop containing a selected area\n",
    "\n",
    "generate crops (light blue) that encompass the yellow square. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from madpack.transforms.spatial import random_crop_special_by_map\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "\n",
    "images = []\n",
    "_, ax = plt.subplots(1, 5, figsize=(15, 3))\n",
    "a = torch.zeros(200, 200).bool()\n",
    "pos = torch.randint(0, 200-30, (2,))\n",
    "\n",
    "# print(pos)\n",
    "a[pos[0]: pos[0]+ 30, pos[1]: pos[1]+30] = 1\n",
    "\n",
    "for i in range(5):\n",
    "    off_y, off_x, size, iters = random_crop_special_by_map(a, (80,40))\n",
    "    b = torch.zeros_like(a).byte()\n",
    "    b[off_y: off_y + size[0], off_x: off_x + size[1]] = 1\n",
    "    b += 3*a.byte()\n",
    "    # print(b.shape)\n",
    "    images += [b]\n",
    "\n",
    "    ax[i].imshow(b)\n",
    "    ax[i].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### adaptive size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(1, 5, figsize=(15, 3))\n",
    "for i in range(5):\n",
    "    off_y, off_x, size, iters = random_crop_special_by_map(a, (80,20), adapt_size=True)\n",
    "    b = torch.zeros_like(a).byte()\n",
    "    b[off_y: off_y + size[0], off_x: off_x + size[1]] = 1\n",
    "    b += 3*a.byte()\n",
    "    # print(b.shape)\n",
    "    images += [b]\n",
    "\n",
    "    ax[i].imshow(b)\n",
    "    ax[i].axis('off')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
